<!--?xml version="1.0" encoding="UTF-8"?--><html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops"><head></head>
  <body><!--StartFragment--><p>Algorithm : Naive Bayes Classifier Algorithm</p><p>Name: Geetika Gautam</p><p>Enrolt no: 12303008</p><p>Date Of Submission: 26-03-2014</p><p><br></p><p></p><p class="">The idea of the Naive Bayes Classifier algorithm is based on the so called Bayesian theorem. The Bayesian theorem is based on probability, in that it find the outcomes of the given input in the probability manner .The Naive Bayes algorithm measure the probability of the given huge data &nbsp;and is to combine the various features in the dataset for the classification. Each content word in the input text contributes for the classification process. It can be trained very efficiently using existing dataset to predict the probability of an event.<o:p></o:p></p><p>&nbsp;</p><p class="">Advantage: Requires a small amount of training data to estimate the parameters<o:p></o:p></p><p>&nbsp;</p><h2>“A&nbsp;Naive Bayes classifier&nbsp;is a simple probabilistic theorem and can be represented as a supervised&nbsp;learning method. In the probability theory, if two events&nbsp;are&nbsp;independent&nbsp;then it means that the occurrence of one does not affect the probability of the other. This Bayesian classifier makes use of statistical approach by applying&nbsp;Bayes’s&nbsp;with strong (naive) independence&nbsp;assumptions.”<o:p></o:p></h2><p>&nbsp; &nbsp;</p><p class=""><b>And the some reason behind the Bayesian Classification: Why?<o:p></o:p></b></p><p></p><ol><li>Probabilistic learning:&nbsp; Calculate explicit probabilities for hypothesis, among the most practical approaches to certain types of learning problems</li><li>Incremental: Each training example can incrementally increase/decrease the probability that a hypothesis is correct.&nbsp; Prior knowledge can be combined with observed data.</li><li>Probabilistic prediction:&nbsp; Predict multiple hypotheses, weighted by their probabilities</li><li>Standard: Even when Bayesian methods are computationally intractable, they can provide a standard optimal decision making, against other methods which can be measured</li><li>Imbalanced dataset: This is due to the ability of the majority samples to dominate the performance of a classifier<br>.<o:p></o:p></li></ol><p>&nbsp; Bayesian Network is a network that represents the probability of joint distribution between variables. A Bayesian network called “naive” when the relations between variables are conditionally independent. Figure 1 shows the graphical representation for Naive Bayes network with conditionally independent assumption. The figure shows that if Class C is known, then the level of variable X1 will depend on expression value in C and independent from other variables; X2, X3,…, Xi.<span class="Apple-converted-space">&nbsp;</span></p><p><br></p><!--EndFragment-->
</body></html>